{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dbb65ea",
   "metadata": {},
   "source": [
    "# Experiment: Extract Landmarks from Raw Video with MediaPipe Holistic\n",
    "\n",
    "This notebook demonstrates how to extract pose, face, and hand landmarks from a raw video using MediaPipe Holistic, and save the results in the same .parquet format as the competition dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa41f7",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Import necessary libraries for video processing, landmark extraction, and saving to .parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9478220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f55f8",
   "metadata": {},
   "source": [
    "## 2. Set Experiment Parameters\n",
    "Define input video path, output directory, participant ID, and frame sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356e2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment parameters\n",
    "input_video_path = \"Hailuo_Video_a male person performing sign _434390501941637128.mp4\"  # Change to your video file\n",
    "output_dir = \"after/\"\n",
    "participant_id = \"demo_user\"\n",
    "sign_label = \"demo_sign_after\"\n",
    "frame_sample_rate = 1  # Process every frame (set >1 to skip frames)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_parquet_path = os.path.join(output_dir, f\"{participant_id}_{sign_label}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e7412a",
   "metadata": {},
   "source": [
    "## 3. Load Raw Video\n",
    "Use OpenCV to load the video and iterate through its frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a41168bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames in video: 141\n"
     ]
    }
   ],
   "source": [
    "# Load raw video\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"Total frames in video: {frame_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ffdb0f",
   "metadata": {},
   "source": [
    "## 4. Run MediaPipe Holistic Landmark Extraction\n",
    "Initialize MediaPipe Holistic and process each frame to extract pose, face, and hand landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05ae9700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model to /root/miniconda/envs/pytorch_env/lib/python3.10/site-packages/mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1760423740.713461   68051 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760423740.807370   68051 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760423740.819069   68057 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760423740.819275   68051 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760423740.819368   68066 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760423740.828559   68057 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760423740.840035   68051 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760423740.840442   68066 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1760423740.859523   68062 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "W0000 00:00:1760423740.859523   68062 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames processed: 141\n"
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic = mp_holistic.Holistic(static_image_mode=False, model_complexity=2)\n",
    "\n",
    "landmark_rows = []\n",
    "frame_idx = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if frame_idx % frame_sample_rate != 0:\n",
    "        frame_idx += 1\n",
    "        continue\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = holistic.process(image)\n",
    "    # Helper to extract and append landmarks\n",
    "    def extract_landmarks(landmarks, ltype):\n",
    "        if landmarks:\n",
    "            for idx, lm in enumerate(landmarks.landmark):\n",
    "                landmark_rows.append({\n",
    "                    'frame': frame_idx,\n",
    "                    'type': ltype,\n",
    "                    'landmark_index': idx,\n",
    "                    'x': lm.x,\n",
    "                    'y': lm.y,\n",
    "                    'z': lm.z,\n",
    "                    'visibility': getattr(lm, 'visibility', np.nan)\n",
    "                })\n",
    "    extract_landmarks(results.face_landmarks, 'face')\n",
    "    extract_landmarks(results.left_hand_landmarks, 'left_hand')\n",
    "    extract_landmarks(results.right_hand_landmarks, 'right_hand')\n",
    "    extract_landmarks(results.pose_landmarks, 'pose')\n",
    "    frame_idx += 1\n",
    "cap.release()\n",
    "holistic.close()\n",
    "print(f\"Total frames processed: {frame_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590f5282",
   "metadata": {},
   "source": [
    "## 5. Format Extracted Landmarks to DataFrame\n",
    "Convert the extracted landmarks for each frame into a pandas DataFrame matching the dataset schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "182d8480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   frame    row_id  type  landmark_index         x         y         z  \\\n",
      "0      0  0-face-0  face               0  0.493450  0.357994 -0.013742   \n",
      "1      0  0-face-1  face               1  0.494137  0.320811 -0.029118   \n",
      "2      0  0-face-2  face               2  0.493934  0.331576 -0.014462   \n",
      "3      0  0-face-3  face               3  0.490116  0.285871 -0.023331   \n",
      "4      0  0-face-4  face               4  0.494288  0.309959 -0.031364   \n",
      "\n",
      "   visibility  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         0.0  \n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "landmarks_df = pd.DataFrame(landmark_rows)\n",
    "# Add row_id column for uniqueness\n",
    "landmarks_df['row_id'] = landmarks_df.apply(lambda r: f\"{r['frame']}-{r['type']}-{r['landmark_index']}\", axis=1)\n",
    "# Reorder columns to match dataset\n",
    "landmarks_df = landmarks_df[['frame', 'row_id', 'type', 'landmark_index', 'x', 'y', 'z', 'visibility']]\n",
    "print(landmarks_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443ffe1f",
   "metadata": {},
   "source": [
    "## 6. Save Landmarks to .parquet File\n",
    "Save the DataFrame to a .parquet file using pandas and pyarrow, matching the dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a0334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted landmarks to after/demo_user_demo_sign_after.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save to .parquet file\n",
    "landmarks_df.to_parquet(output_parquet_path, index=False)\n",
    "print(f\"Saved extracted landmarks to {output_parquet_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
